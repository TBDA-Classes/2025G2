SQL DATABASE AND DATA ANALYSIS
==============================

Introduction
------------
The project relies on two PostgreSQL databases:

1. **Production Database:**  
   Large-scale raw CNC sensor dataset.  


2. **Aggregation Database:**  
   Lightweight, query-optimized database built via custom ETL processes.

The Data Analysis Team was responsible for understanding the production schema,
extracting relevant information, and enabling efficient querying through aggregation.


CNC Machine Status Semantics
----------------------------
A CNC machine can be in one of several states:

* **RUN** – actively processing a part  
* **IDLE** – powered on but not processing  
* **DOWN** – emergency stop or failure  
 

Raw data reflects:

* Status changes  
* Temperature samples  
* Program execution logs  
* Power usage  
* Alerts and timestamps  


Data Extraction Strategy
------------------------
The production database schema contains:

* ``machine_state```
   For Machine Operation: The query for this part identifies if 
   the machine is operating based on the variable Machine_in_operation, 
   which is a boolean.

   For Machine Utilization: The query used analyzes variable changes in
   fixed 10-minute blocks to determine the utilization level of the
   machine. If there are no variable changes within a block, the
   machine is considered to be turned off. In the case that there are
   30 variable changes or less in a block, the machine is considered
   to be Idle. Finally, if there are more than 30 variable changes 
   registered within the block, the machine is considered to be running.
* ``temperature_readings``
   The query used retrieves the values of temperature variables
   registered from different parts of the machine. It is important to
   note that the query excludes non-significant temperature variables
   (in other words, variables that only register zeros or NaNs).  
* ``alerts``  
* ``program_usage``
   The query used identifies the states registered for the variable
   Program Status (Prog_Status). It assumes a persistence logic: 
   once a state is registered, the machine remains in that state 
   until a new one is recorded. Crucially, it also retrieves the 
   last state from the previous day to account for the time starting 
   exactly at 00:00:00. Finally, the query calculates the total 
   duration in seconds for each state during the entire day.
* ``power_consumption``
   Since the database doesn’t give us real energy values, we estimate
   it using the motor utilization percentages. Each motor has a known
   nominal power (kW), so we assume that its real power at any moment
   is (utilization% × nominal kW). We then calculate how long each
   utilization value stays active and convert that into energy (kWh).
   Finally, we culminate the first query by adding up all these segments
   and then grouping the results by hour to create the hourly energy
   chart.

   The second query used simply retrieves all temperature values from 
   thesensors we found to be reliable. We convert the timestamps 
   from milliseconds to seconds and filter the data to a specific 24 
   hour period. The result is a clean list of temperature readings 
   over time, which is what the frontend needs for plotting the 
   temperature graph.

The Data Analysis Team ingested these tables to compute:

* 24-hour status distributions  
* Per-shift aggregations  
* Program history  
* Temperature history  
* Energy consumption patterns  
* Emergent alerts by severity  
* Coverage of available dates  


Data Aggregation Strategy
---------------------------
The production database contains millions of rows. To ensure interactive performance in the frontend:

* ETL scripts extract raw sensor data
* Transform it through SQL and Python logic
* Load computed summaries into the aggregation DB

Indexing Strategy
~~~~~~~~~~~~~~~~~~
B-Tree indexes are used for reducing lookup time significantly.

Views
~~~~~
The ``v_data_status`` view provides:

* Global first/last date across all aggregated tables
* Record counts per table (sensors, utilization, alerts, programs, energy)
* Used by the frontend datepicker to restrict selectable dates

Connecting to PostgreSQL
------------------------
Example:

::

   psql -h 138.100.82.184 -U lectura -d <database> -p 2345


Useful psql commands:

* ``\l`` – list databases  
* ``\dt`` – list tables
* ``\dv`` – list views
* ``\d table`` – describe schema
* ``\conninfo`` – connection info

JSON and SQL Operations
------------------------
Relevant PostgreSQL operators used during analysis:

* ``->`` and ``->>``
* ``jsonb_array_elements``
* ``jsonb_each_text``
* Window functions (``PARTITION BY``)
* ``GROUP BY``, ``HAVING``
These allowed the team to transform nested or
semi-structured sensor logs into usable units for aggregation.

Shift-Based Interpretation
--------------------------
Production teams work in:

* **Shift 1** – 06:00–14:00  
* **Shift 2** – 14:00–22:00  
* **Shift 3** – 22:00–06:00  

Aggregations produce metrics for each shift, consumed by:

* Dashboard  
* Energy view  
* Alerts distribution  

See :doc:`queries` for SQL queries used during analysis and validation.